# CompresiÃ³n de ImÃ¡genes mediante Quadtrees Guiados por Redes Neuronales Convolucionales

**Trabajo de TÃ­tulo para IngenierÃ­a Civil InformÃ¡tica**  
**Autor:** Felipe AndrÃ© Marchant Vargas  
**Profesor GuÃ­a:** Roberto LeÃ³n, PhD. Computer Science
**Profesor Co-GuÃ­a:** Jorge DÃ­az, MSc. Computer Science
**Universidad:** Universidad TÃ©cnica Federico Santa MarÃ­a

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange.svg)![License](https://img.shields.io/badge/License-MIT-green.svg)

---

## ğŸ“– Resumen

Este proyecto aborda el problema de la compresiÃ³n de imÃ¡genes con pÃ©rdida, buscando optimizar la calidad perceptual en lugar de mÃ©tricas puramente matemÃ¡ticas. Los mÃ©todos tradicionales como JPEG degradan la calidad de manera uniforme, mientras que los algoritmos de Quadtree estÃ¡ndar carecen de entendimiento semÃ¡ntico.

Esta memoria de tÃ­tulo propone el diseÃ±o y la evaluaciÃ³n de un algoritmo de compresiÃ³n hÃ­brido que utiliza un modelo de Red Neuronal Convolucional (CNN) para generar un **mapa de prominencia visual** (_saliency map_). Este mapa guÃ­a el proceso de subdivisiÃ³n adaptativa de un Quadtree, asignando mayor detalle y profundidad a las regiones de interÃ©s semÃ¡ntico, y aplicando una compresiÃ³n mÃ¡s agresiva en las zonas menos relevantes para la percepciÃ³n humana.

## ğŸ¯ Objetivos del Proyecto

### Objetivo General

DiseÃ±ar y evaluar un algoritmo de compresiÃ³n de imÃ¡genes basado en la subdivisiÃ³n adaptativa de Quadtrees, utilizando un mapa de prominencia visual generado por una Red Neuronal Convolucional para mejorar la calidad perceptual frente a mÃ©todos estÃ¡ndar.

### Objetivos EspecÃ­ficos

1.  **Desarrollar el componente base** que permita el cÃ¡lculo de la prominencia de imÃ¡genes a partir de una CNN pre-entrenada.
2.  **Implementar un algoritmo de compresiÃ³n hÃ­brido** basado en Quadtree y guiado por la prominencia visual.
3.  **Evaluar el algoritmo propuesto** en base a la calidad perceptual (usando mÃ©tricas como SSIM y LPIPS) y compararlo con mÃ©todos estÃ¡ndar como JPEG y Quadtree tradicional a tasas de compresiÃ³n equivalentes.

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n del Entorno

Sigue estos pasos para configurar el entorno de desarrollo en un sistema basado en Debian/Ubuntu (como Pop!\_OS).

**1. Clonar el repositorio:**

```bash
git clone [URL-DE-TU-REPOSITORIO]
cd [NOMBRE-DEL-REPOSITORIO]
```

**2. Crear y activar un entorno virtual de Python:**

```bash
python3 -m venv venv
source venv/bin/activate
```

_Para desactivar el entorno, simplemente ejecuta `deactivate`._

**3. Instalar las dependencias:**
Todas las bibliotecas necesarias estÃ¡n listadas en `requirements.txt`.

```bash
pip install -r requirements.txt
```

_(Nota: AsegÃºrate de tener instalados los drivers de NVIDIA y el CUDA Toolkit si vas a usar la GPU)._

## ğŸš€ Uso

AquÃ­ se detallan los comandos para ejecutar los procesos principales del proyecto.

**1. Comprimir una imagen:**

```bash
python main.py compress \
    --input path/to/your/image.jpg \
    --output path/to/compressed_file.qt \
    --model path/to/saliency_model.pth \
    --threshold 0.95
```

**2. Descomprimir una imagen:**

```bash
python main.py decompress \
    --input path/to/compressed_file.qt \
    --output path/to/reconstructed_image.png
```

**3. Ejecutar la evaluaciÃ³n de mÃ©tricas:**

```bash
python evaluate.py \
    --dataset path/to/image_dataset/ \
    --methods jpeg cnn_quadtree traditional_quadtree \
    --output results/evaluation.csv
```

## ğŸ“‚ Estructura del Repositorio

```
.
â”œâ”€â”€ data/                  # Contiene los datasets de imÃ¡genes para entrenamiento y prueba.
â”œâ”€â”€ notebooks/             # Jupyter notebooks para experimentaciÃ³n, anÃ¡lisis y visualizaciÃ³n.
â”œâ”€â”€ results/               # Almacena las imÃ¡genes de salida, grÃ¡ficos y reportes de mÃ©tricas.
â”œâ”€â”€ src/                   # CÃ³digo fuente principal del proyecto.
â”‚   â”œâ”€â”€ compression.py     # LÃ³gica de compresiÃ³n y descompresiÃ³n con Quadtree.
â”‚   â”œâ”€â”€ model.py           # DefiniciÃ³n del modelo de CNN para prominencia visual.
â”‚   â”œâ”€â”€ utils.py           # Funciones de ayuda (cÃ¡lculo de mÃ©tricas, I/O de imÃ¡genes).
â”‚   â””â”€â”€ ...
â”œâ”€â”€ main.py                # Script principal para ejecutar la compresiÃ³n/descompresiÃ³n.
â”œâ”€â”€ evaluate.py            # Script para correr las evaluaciones de rendimiento.
â”œâ”€â”€ requirements.txt       # Lista de dependencias de Python para `pip`.
â””â”€â”€ README.md              # Este archivo.
```

## ğŸ§  MetodologÃ­a Propuesta

El algoritmo sigue un enfoque de **Muestreo Adaptativo** y **ReconstrucciÃ³n Continua**:

1.  **AnÃ¡lisis SemÃ¡ntico:** La imagen entra a una CNN que genera un mapa de calor (0.0 a 1.0), indicando quÃ© pÃ­xeles son perceptualmente relevantes.
2.  **Muestreo HÃ­brido:** Se construye un Quadtree. La decisiÃ³n de dividir un cuadrante depende de una funciÃ³n de costo que combina la varianza del color y la prominencia media.

    - Zonas Importantes: Umbral de error bajo â†’ Alta densidad de nodos (malla fina).

    - Fondos: Umbral de error alto â†’ Baja densidad (malla gruesa).

3.  **RestricciÃ³n TopolÃ³gica:** Se aplica una regla de balanceo para asegurar que ningÃºn nodo tenga una diferencia de nivel mayor a 1 con sus vecinos, evitando grietas en la reconstrucciÃ³n.
4.  **ReconstrucciÃ³n Continua:** En lugar de pintar bloques sÃ³lidos, se utiliza InterpolaciÃ³n Bilineal basada en los vÃ©rtices del Quadtree. Esto genera una imagen suave y libre de artefactos de bloque ($C^0$ continuity).

## ğŸ“„ Licencia

Este proyecto se distribuye bajo la Licencia MIT. Consulta el archivo `LICENSE` para mÃ¡s detalles.
